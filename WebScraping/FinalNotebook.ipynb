{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff4a42c-4bad-4e36-b437-920906e23082",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests --upgrade --quiet\n",
    "!pip install beautifulsoup4 --upgrade --quiet\n",
    "!pip install pandas --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fae78c50-8f52-44b8-82ef-6188894543e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f6fa32d-0e59-4c0c-99a5-2a0f0ef7f840",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_url = 'https://github.com/topics'\n",
    "base_url = 'https://github.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45569ac4-ae36-4b20-93b5-42f3fc66ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(topics_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d77bf94-c3c5-4ed0-b503-b8733c87b725",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_contents = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "988a664b-ef0b-4070-af9f-86a571d6af98",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = BeautifulSoup(page_contents, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f8c21b3-876e-4f33-85db-a65f60ec7a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_star_count(stars_str):\n",
    "    stars_str = stars_str.strip()\n",
    "    if stars_str[-1] == 'k':\n",
    "        return int(float(stars_str[:-1]) * 1000)\n",
    "    return int(stars_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cf6aa28-23e2-428e-882e-05eeb4095a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_page(topic_url):\n",
    "    # Downlaod the page \n",
    "    response = requests.get(topic_url)\n",
    "    # Check successful response\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    # Parse using Beautiful Soup\n",
    "    topic_doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return topic_doc\n",
    "\n",
    "def get_repo_info(h1_tag, star_tag):\n",
    "    #returns all the required info about a repository\n",
    "    a_tags = h1_tag.find_all('a')\n",
    "    username = a_tags[0].text.strip()\n",
    "    repo_name = a_tags[1].text.strip()\n",
    "    repo_url = base_url + a_tags[1]['href']\n",
    "    stars = parse_star_count(star_tag.text.strip())\n",
    "    return username, repo_name, stars, repo_url\n",
    "\n",
    "def get_topic_repos(topic_doc):\n",
    "    # Get the h1 tags containing repo title, repo URL, and username\n",
    "    h1_selection_class = 'f3 color-fg-muted text-normal lh-condensed'\n",
    "    repo_tags = topic_doc.find_all('h3', {'class': h1_selection_class})\n",
    "    # Get star tags\n",
    "    star_tags = topic_doc.find_all('span', {'class': 'Counter js-social-count'})\n",
    "\n",
    "    topic_repos_dict = {\n",
    "        'username' : [],\n",
    "        'repo_name' : [],\n",
    "        'stars': [],\n",
    "        'repo_url' : []\n",
    "    }\n",
    "    \n",
    "    # Get repo info\n",
    "    for i in range(len(repo_tags)):\n",
    "        repo_info = get_repo_info(repo_tags[i], star_tags[i])\n",
    "        topic_repos_dict['username'].append(repo_info[0])\n",
    "        topic_repos_dict['repo_name'].append(repo_info[1])\n",
    "        topic_repos_dict['stars'].append(repo_info[2])\n",
    "        topic_repos_dict['repo_url'].append(repo_info[3])\n",
    "\n",
    "    return pd.DataFrame(topic_repos_dict)\n",
    "\n",
    "def scrape_topic(topic_url, path):\n",
    "    if os.path.exists(path):\n",
    "        print(\"The file {} already exists. Skipping...\".format(path))\n",
    "        return\n",
    "    topic_df = get_topic_repos(get_topic_page(topic_url))\n",
    "    \n",
    "    topic_df.to_csv(path, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25c8ecf2-1f21-493d-a33d-3a0eb421be1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_titles(doc):\n",
    "    selection_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "    topic_title_tags = doc.find_all('p', {'class' : selection_class})\n",
    "    topic_titles = []\n",
    "    for tag in topic_title_tags:\n",
    "        topic_titles.append(tag.text)\n",
    "    return topic_titles\n",
    "\n",
    "def get_topic_descs(doc):\n",
    "    desc_selector = 'f5 color-fg-muted mb-0 mt-1'\n",
    "    topic_desc_tags = doc.find_all('p', {'class', desc_selector})\n",
    "    topic_descs = []\n",
    "    for tag in topic_desc_tags:\n",
    "        topic_descs.append(tag.text.strip())\n",
    "    return topic_descs\n",
    "\n",
    "def get_topic_urls(doc):\n",
    "    topic_link_tags = doc.find_all('a', {'class': 'no-underline flex-1 d-flex flex-column'})\n",
    "    topic_urls = []\n",
    "    base_url = 'https://github.com'\n",
    "    for tag in topic_link_tags:\n",
    "        topic_urls.append(base_url + tag['href'])\n",
    "    return topic_urls\n",
    "\n",
    "def scrape_topics():\n",
    "    topics_url = 'https://github.com/topics'\n",
    "    response = requests.get(topics_url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    topics_dict = {\n",
    "        'title': get_topic_titles(doc), \n",
    "        'description': get_topic_descs(doc),\n",
    "        'url': get_topic_urls(doc)\n",
    "    }\n",
    "    return pd.DataFrame(topics_dict)\n",
    "\n",
    "def scrape_topic(topic_url, topic_name):\n",
    "    topic_df = get_topic_repos(get_topic_page(topic_url))\n",
    "    topic_df.to_csv(topic_name + '.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99a92eaa-93a0-43c0-999c-d184aab550f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics_repos():\n",
    "    print('Scraping list of topics')\n",
    "    topics_df = scrape_topics()\n",
    "\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    \n",
    "    for index, row in topics_df.iterrows():\n",
    "        print('Scraping top repos for \"{}\"'.format(row['title']))\n",
    "        scrape_topic(row['url'], 'data/{}.csv'.format(row['title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fdd12ab-e9d0-4ab6-ab65-f74703e408d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping list of topics\n",
      "Scraping top repos for \"3D\"\n",
      "Scraping top repos for \"Ajax\"\n",
      "Scraping top repos for \"Algorithm\"\n",
      "Scraping top repos for \"Amp\"\n",
      "Scraping top repos for \"Android\"\n",
      "Scraping top repos for \"Angular\"\n",
      "Scraping top repos for \"Ansible\"\n",
      "Scraping top repos for \"API\"\n",
      "Scraping top repos for \"Arduino\"\n",
      "Scraping top repos for \"ASP.NET\"\n",
      "Scraping top repos for \"Awesome Lists\"\n",
      "Scraping top repos for \"Amazon Web Services\"\n",
      "Scraping top repos for \"Azure\"\n",
      "Scraping top repos for \"Babel\"\n",
      "Scraping top repos for \"Bash\"\n",
      "Scraping top repos for \"Bitcoin\"\n",
      "Scraping top repos for \"Bootstrap\"\n",
      "Scraping top repos for \"Bot\"\n",
      "Scraping top repos for \"C\"\n",
      "Scraping top repos for \"Chrome\"\n",
      "Scraping top repos for \"Chrome extension\"\n",
      "Scraping top repos for \"Command-line interface\"\n",
      "Scraping top repos for \"Clojure\"\n",
      "Scraping top repos for \"Code quality\"\n",
      "Scraping top repos for \"Code review\"\n",
      "Scraping top repos for \"Compiler\"\n",
      "Scraping top repos for \"Continuous integration\"\n",
      "Scraping top repos for \"C++\"\n",
      "Scraping top repos for \"Cryptocurrency\"\n",
      "Scraping top repos for \"Crystal\"\n"
     ]
    }
   ],
   "source": [
    "scrape_topics_repos()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
